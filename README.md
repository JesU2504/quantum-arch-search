# Quantum Architecture Search via Adversarial Co‑Evolution

Co‑evolutionary quantum circuit search with two agents: an Architect (constructs circuits) and a Saboteur (injects noise). The adversarial game acts as a parameter‑free, dynamic regularizer that discourages bloat and promotes robustness.

This repository contains a turnkey pipeline to train baseline and adversarial agents, generate co‑evolution plots, and compare robustness of “vanilla” vs “robust” circuits.


## Research goal (for the talk)

We demonstrate that Adversarial Co‑Evolution is a parameter‑free regularizer that outperforms static penalty methods on stability, robustness, and Pareto efficiency. See `ExpPlan.md` for the detailed experimental plan and rationale.


## Default Target: n-Controlled Toffoli Gates

**New default**: All experiments now use n-controlled Toffoli (multi-controlled NOT) gates as the compilation target:
- **2 qubits**: CNOT gate
- **3 qubits**: Toffoli (CCNOT) gate
- **4 qubits**: CCCNOT gate  
- **n qubits**: (n-1)-controlled NOT gate

The Toffoli gate target provides a more challenging benchmark than GHZ state preparation, as it requires precise multi-qubit controlled operations. GHZ state preparation remains available as a legacy option via `get_ghz_state()`.


## Install

Tested with Python 3.12 on Linux.

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

Dependencies (pinned): Cirq, Gymnasium, Stable‑Baselines3, NumPy, Matplotlib.


## Quick demo (3-qubit Toffoli, full pipeline)

Runs baseline architect training, saboteur‑only training, adversarial co‑evolution for a couple of generations, plotting, and a robustness comparison.

```bash
python run_experiments.py --preset quick
```

Outputs (example): `results/run_YYYYMMDD-HHMMSS/`
- `baseline/`
	- `circuit_vanilla.json` — champion vanilla (noiseless) circuit
	- `architect_fidelities.txt`, `architect_steps.txt`, `architect_training_progress.png`
- `saboteur/`
	- `saboteur_trained_on_architect_model.zip`
	- `saboteur_trained_on_architect_fidelities.txt`, `saboteur_trained_on_architect_steps.txt`, `...training_progress.png`
- `adversarial/adversarial_training_*/`
	- `circuit_robust.json` — robust circuit after co‑evolution
	- `coevolution_corrected.png` — corrected co‑evolution plot
- `compare/run_0/`
	- `circuit_vanilla.json`, `circuit_robust.json`
- `compare/`
	- `robust_eval.json`, `attacked_fidelity_samples.csv`, `robustness_comparison.png`


## Reproducing key artifacts

- Co‑evolution plot: produced automatically by the quick pipeline and saved under `adversarial/adversarial_training_*/coevolution_corrected.png`.
- Robustness comparison plot: produced under `compare/robustness_comparison.png` comparing vanilla vs robust circuits under multi‑gate depolarizing attacks.

To scale up, use:

```bash
# Longer runs
python run_experiments.py --preset full --n-qubits 3

# Custom steps (override parts of a preset)
python run_experiments.py --preset quick --baseline-steps 5000 --saboteur-steps 5000 --n-qubits 3
```


## How it works (files you’ll touch)

- Entry point: `run_experiments.py` — orchestrates baseline → saboteur‑only → adversarial → compare.
- Experiment scripts (in `experiments/`):
	- `train_architect_ghz.py`: baseline Architect for GHZ preparation
	- `train_saboteur_only.py`: Saboteur learns to attack the baseline circuit
	- `train_adversarial.py`: co‑evolution between Architect and Saboteur
	- `plot_coevolution.py`: renders corrected co‑evolution plots
	- `compare_circuits.py`: aggregates vanilla vs robust robustness metrics/plots
	- `vqe_architecture_search_example.py`: VQE architecture search demo
	- `vqe_h4_benchmark.py`: H4 benchmark comparing ansatzes (Part 4)
- Environments (in `src/qas_gym/envs/`):
	- `architect_env.py`: reward‑shaped ArchitectEnv and AdversarialArchitectEnv
	- `saboteur_env.py`: SaboteurMultiGateEnv with attack budget and vectorized noise actions
	- `qas_env.py`: shared circuit/env utilities
	- `vqe_architect_env.py`: VQE environment for molecular ground state optimization


## Mapping to the Experimental Plan

The repository ships the core pipeline and figures for Parts 2 and 7, and a strong baseline for Part 3. For completeness, the full plan is in `ExpPlan.md`.

- Part 1 (λ‑sweep brittleness, static penalty): not included as code here. Our method avoids λ entirely; reproducing tuned static‑penalty sweeps would require a simple reward variant (R = Fidelity − λ·Cost) and a small sweep harness.
- Part 2 (Robustness to shift): included — the Saboteur varies attacks during training; robustness comparison is generated by `compare_circuits.py` (multi‑gate depolarizing). Extending to asymmetric/coherent noise sweeps is straightforward in that script.
- Part 3 (Pareto frontier): partially included — we output fidelity and circuits. To plot CNOT‑count vs fidelity, compute CNOT count from `circuit_*.json` and scatter. If desired, we can add explicit CNOT logging in env info.
- Part 4 (VQE on H4): **fully implemented** — see VQE Architecture Search section below.
- Part 5 (Overhead analysis): not included as an automated benchmark; you can wrap wall‑clock timing around each phase in `run_experiments.py`.
- Part 6 (QEC resource plot): not included in this repository. See `ExpPlan.md` for the argument framing; adding a simple bar‑chart script to visualize physical‑qubit overhead is straightforward.
- Part 7 (Verification): included conceptually — saboteur‑only run demonstrates fidelity degradation and learning. A dedicated `verify_saboteur` script can be added or adapted if you want a one‑shot check on a perfect GHZ circuit.


## VQE Architecture Search (Part 4)

This repository includes full support for VQE-based quantum chemistry experiments using the `VQEArchitectEnv` environment.

### VQEArchitectEnv Overview

The `VQEArchitectEnv` is a Gymnasium environment where an RL agent designs quantum circuits to minimize molecular Hamiltonian energy:

- **Molecules supported**: H2 (2 qubits) and H4 (4 qubits at 1.5 Å stretched geometry)
- **Action space**: Discrete actions for parameterized rotation gates (Rx, Ry, Rz on each qubit), CNOT gates (all ordered pairs), and a DONE action to terminate
- **Classical optimization**: At episode end, rotation angles are optimized using scipy's L-BFGS-B with multiple restarts
- **Reward**: Based on optimized energy relative to FCI ground state, with optional CNOT penalty

### Quick VQE Demo

```bash
# Quick demo on H2 (2 qubits)
python experiments/vqe_architecture_search_example.py --molecule H2 --episodes 10

# H4 benchmark (4 qubits, Part 4 of ExpPlan.md)
python experiments/vqe_architecture_search_example.py --molecule H4 --episodes 50

# Using greedy agent instead of random
python experiments/vqe_architecture_search_example.py --molecule H2 --agent greedy --episodes 5
```

### VQE H4 Benchmark

For the full H4 benchmark comparing UCCSD, Hardware Efficient, and Adversarial ansatzes:

```bash
python experiments/vqe_h4_benchmark.py --max-iterations 200 --n-seeds 3
```

Win condition (from ExpPlan.md): Achieve chemical accuracy (1.6 mHa) with fewer CNOTs than UCCSD.

### Using VQEArchitectEnv Programmatically

```python
from src.qas_gym.envs import VQEArchitectEnv

# Create environment for H4 at 1.5 Å bond distance
env = VQEArchitectEnv(
    molecule="H4",
    bond_distance=1.5,
    max_timesteps=15,
    log_dir="results/my_vqe_run"  # Optional: enable logging
)

# Reset and run episode
obs, info = env.reset(seed=42)
print(f"Initial (HF) energy: {info['initial_energy']:.4f} Ha")

# Agent adds gates (example: Ry on each qubit + CNOTs)
for action in [4, 5, 6, 7, 12, 13]:  # Ry gates then CNOTs
    obs, reward, terminated, truncated, info = env.step(action)
    if terminated:
        break

# Terminate episode
obs, reward, terminated, truncated, info = env.step(24)  # DONE action for H4

print(f"Optimized energy: {info['optimized_energy']:.4f} Ha")
print(f"Energy error: {info['energy_error']*1000:.2f} mHa")
print(f"Chemical accuracy achieved: {info['chemical_accuracy_achieved']}")

# Get best circuit found
circuit, energy = env.get_best_circuit()
```

### Action Space Encoding

For a molecule with `n` qubits:
- Actions 0 to n-1: Rx gates on qubits 0, 1, ..., n-1
- Actions n to 2n-1: Ry gates on each qubit
- Actions 2n to 3n-1: Rz gates on each qubit
- Actions 3n to 3n + n(n-1) - 1: CNOT gates (all ordered pairs)
- Last action: DONE (terminate episode)

### Logging and Reproducibility

When `log_dir` is specified, the environment logs:
- Circuit architecture (gate sequence)
- Initial and optimized rotation angles
- CNOT and total gate counts
- Optimization details (iterations, success)
- Initial and final energies
- Whether chemical accuracy was achieved

All logs are saved in JSON format for full reproducibility.


## Tips and troubleshooting

- Seeds: pass `--seed <int>` to `run_experiments.py` for reproducibility.
- QuBits: use `--n-qubits 3` (default). Higher qubit counts raise simulation cost.
- Results hygiene: archive or prune older runs in `results/` to keep the bundle small.
- Gym vs Gymnasium: this project uses Gymnasium; if you see a warning about Gym, it’s safe to ignore.


## Citation

If you use this code, please cite the corresponding talk/paper. For questions or issues, open an issue or contact the authors.



## Changelog

- **VQE Architecture Search (Part 4)**: Fully implemented `VQEArchitectEnv` for molecular ground state optimization. Includes parameterized rotation gates (Rx, Ry, Rz), CNOT gates, classical optimization of rotation angles at episode end, comprehensive logging, and support for H2 and H4 molecules. Added example script and integration tests.
- **Environment Consolidation**: All environments and agents (ArchitectEnv, AdversarialArchitectEnv, Saboteur, VQEArchitectEnv) are now unified under `src/qas_gym/envs/`; duplicate definitions in `src/envs/` have been removed. Import from `src.qas_gym.envs` for all environment classes.

## Statistical Reporting Protocol

This repository follows best-practice statistical reporting for quantum architecture search experiments. All major experiments support multi-seed runs for statistical validity.

### Configuration

- **Number of seeds**: Configurable via `--n-seeds <int>` (default: 5, recommended: 10 for publication).
- **Seed control**: Use `--seed <int>` to set the base random seed for reproducibility.

### Running Multi-Seed Experiments

```bash
# Run full pipeline with 10 seeds per setting
python run_experiments.py --preset full --n-seeds 10 --seed 42

# Run specific experiment with custom seeds
python experiments/lambda_sweep_ghz.py --n-seeds 10 --n-qubits 4

# Parameter recovery with configurable repetitions
python experiments/parameter_recovery.py --n-repetitions 10 --baseline-circuit path/to/circuit.json
```

### Output Structure

Each experiment produces:
- **Per-seed results**: Individual JSON files for each seed (e.g., `lambda_0.001/seed_0_results.json`)
- **Aggregated results**: Combined statistics with mean +/- std
- **Summary files**:
  - `experiment_summary.json`: Machine-readable summary with all parameters
  - `experiment_summary.txt`: Human-readable summary
- **Plots with error bars**: All plots show mean +/- std with sample size annotation (n=...)

### Statistical Metrics

- **Aggregation method**: Mean +/- std (sample standard deviation with ddof=1)
- **Confidence intervals**: 95% CI using t-distribution
- **Success rate**: Wilson score interval for binomial proportions
- **Plots**: Error bars (mean +/- std), faint individual curves overlay, sample size annotation

### Checklist for Multi-Seed Experiments

1. Set `--n-seeds` to at least 5 (ideally 10)
2. Set `--seed` for reproducibility
3. Verify per-seed results are saved in experiment subdirectories
4. Check summary files contain all seeds used and hyperparameters
5. Confirm plots show error bars and sample size annotations
