{
  "paper_title": "Quantum Machine Learning Architecture Search via Deep Reinforcement Learning",
  "authors": [
    "Xin Dai",
    "Tzu-Chieh Wei",
    "Shinjae Yoo",
    "Samuel Yen-Chi Chen"
  ],
  "arxiv_id": "2407.20147",
  "arxiv_url": "https://arxiv.org/abs/2407.20147",
  "paper_pdf": "https://arxiv.org/pdf/2407.20147",
  "venue": "2024 IEEE International Conference on Quantum Computing and Engineering (QCE)",
  "doi": "10.1109/QCE60285.2024.00179",
  "tasks": {
    "task_type": "binary_classification",
    "datasets": [
      {
        "name": "make_classification",
        "source": "sklearn.datasets.make_classification",
        "n_features": 4,
        "n_informative": null,
        "description": "n-dimensional datasets with normally distributed clusters around vertices of hypercube"
      },
      {
        "name": "make_moons",
        "source": "sklearn.datasets.make_moons",
        "n_features": 2,
        "description": "Two interleaving half-moon shaped clusters for non-linear decision boundaries"
      }
    ],
    "train_test_split": null,
    "preprocessing": {
      "encoding": "arctan_embedding",
      "encoding_formula": "theta_i = arctan(f_i), phi_i = arctan(f_i^2)",
      "encoding_gates": "RY(theta_i) and RZ(phi_i) on qubit i"
    }
  },
  "drl_controller": {
    "algorithm": "N-step Double Deep Q-Network (DDQN)",
    "policy_architecture": {
      "type": "MLP",
      "layers": "sequence of linear layers",
      "activation": "LeakyReLU",
      "regularization": "dropout",
      "input": "flattened state vector (4 x L matrix)",
      "output": "Q-values for each action"
    },
    "lr": null,
    "optimizer": null,
    "batch_size": null,
    "num_episodes": {
      "make_classification_fixed": 800,
      "make_classification_adaptive": 1200,
      "make_moons_fixed": 800,
      "make_moons_adaptive": 1200
    },
    "entropy_coeff": null,
    "gamma": {
      "formula": "0.005^(1/L)",
      "description": "L is maximum number of quantum gates allowed"
    },
    "value_loss_coeff": null,
    "target_network_update_frequency": 512,
    "experience_replay_buffer_size": 16384,
    "epsilon_greedy": {
      "initial": 1.0,
      "final": 0.1,
      "decay": "over time"
    },
    "n_steps": null,
    "loss_function": "Smooth_L1"
  },
  "controller_action_state": {
    "action_space_description": "Select quantum gate type (RX, RY, RZ, CNOT) and location (qubit index). For CNOT: control and target qubits. For rotation gates: qubit and axis (X, Y, or Z). Rotation angles optimized by classical optimizer during training.",
    "state_representation_description": "4 x L matrix where L is max layers. First two elements: control and NOT gate locations. Third and fourth elements: rotation gate location and axis. Test accuracy appended after each testing episode."
  },
  "gate_set_and_constraints": {
    "gate_set": ["RX", "RY", "RZ", "CNOT"],
    "parameterized_gates": ["RX", "RY", "RZ"],
    "connectivity": "CNOT between qubit i and (i+1) mod n",
    "max_depth": {
      "make_classification": 20,
      "make_moons": 25
    }
  },
  "inner_loop_optimization": {
    "optimizer": "classical optimizer (not specified)",
    "lr": null,
    "num_epochs": {
      "make_classification": 15,
      "make_moons": 25
    },
    "batch_size": null,
    "loss": "binary cross-entropy",
    "loss_formula": "-(y * log(y_hat) + (1-y) * log(1-y_hat))",
    "stopping_criterion": "fixed number of epochs or desired accuracy reached"
  },
  "reward_design": {
    "primary_reward": "Based on classification accuracy and gate count",
    "reward_function": {
      "case_1": {
        "condition": "y_l >= y_target and l < L",
        "formula": "0.2 * (y_l / y_target) * (L - l)"
      },
      "case_2": {
        "condition": "y_l < y_min and l == L",
        "formula": "-0.2 * ((y_target - y_l) / y_target) * l"
      },
      "case_3": {
        "condition": "otherwise",
        "formula": "clip((y_l - y_{l-1}) / (y_{l-1} + 1e-6) - 0.01 * l, -1.5, 1.5)"
      }
    },
    "complexity_penalties": {
      "gate_penalty_coefficient": 0.01,
      "description": "Reward decreases as more gates are added"
    },
    "adaptive_objective": {
      "enabled": true,
      "initial_target_accuracy": 0.8,
      "target_accuracy_increment": 0.01,
      "train_update_condition": "10 successes in 12 consecutive episodes",
      "test_update_condition": "5 consecutive higher accuracies",
      "epsilon_decay_rate": 0.95
    }
  },
  "compute_budget_and_repeats": {
    "episodes_or_evals_reported": {
      "fixed_target": 800,
      "adaptive_target": 1200
    },
    "num_seeds": null,
    "n_qubits": {
      "make_classification": 4,
      "make_moons": 2
    }
  },
  "reported_metrics": {
    "train_accuracy": true,
    "test_accuracy": true,
    "num_gates": true,
    "reward": true,
    "best_results": {
      "make_classification_adaptive_1200ep": {
        "test_accuracy": 0.93,
        "num_gates": 4
      }
    },
    "classical_baselines": {
      "make_classification": {
        "logistic_regression": {
          "accuracy": 0.903,
          "parameters": 5
        },
        "svm": {
          "accuracy": 0.903,
          "support_vectors": 110
        }
      },
      "make_moons": {
        "logistic_regression": {
          "accuracy": 0.825,
          "parameters": 3
        },
        "svm_rbf": {
          "accuracy": 1.0,
          "support_vectors": 44
        }
      }
    }
  },
  "software_frameworks": {
    "quantum_simulation": "TensorCircuit",
    "deep_learning": "PyTorch",
    "datasets": "scikit-learn"
  },
  "notes": [
    "Learning rate (lr) for DDQN not explicitly specified in paper",
    "Batch size for RL training not explicitly specified in paper",
    "Number of seeds/repetitions not explicitly stated",
    "Train/test split ratio not specified",
    "Optimizer for DDQN (Adam, SGD, etc.) not specified",
    "N-step value in N-step DDQN not specified",
    "Specific MLP architecture (hidden layer sizes) not detailed",
    "Inner-loop optimizer for quantum circuit parameters not specified",
    "Inner-loop batch size not specified",
    "Adaptive search shows dynamic adjustment of y_target starting from 0.8 or 0.85",
    "Paper focuses on noise-free simulations; noisy device extension discussed as future work",
    "Action space scales as 3n + n(n-1) = O(n^2) for n qubits"
  ]
}
